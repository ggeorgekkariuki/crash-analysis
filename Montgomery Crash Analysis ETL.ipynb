{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e567d75",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191de858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0621b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data into a dataframe\n",
    "df_accidents = pd.read_json('crash_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0263b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataUnderstanding:\n",
    "    \"\"\"This class gives the general quick overview of a Dataframe\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "        \n",
    "    def print_shape(self, title=\"Record\"):\n",
    "        \"\"\"This function gives us the shape of the data\"\"\"\n",
    "        print(title.upper())\n",
    "        print(\"-\"*len(title))\n",
    "        print(\"There are\", self.df.shape[0], \"rows\")\n",
    "        print(\"There are\", self.df.shape[1], \"columns\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    def information(self, title=\"Info\"):\n",
    "        \"\"\"This function gives us the descriptive information of the data\"\"\"\n",
    "        print(title.upper())\n",
    "        print(\"-\"*len(title))\n",
    "        print(self.df.info())\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    def duplicate_values(self, title=\"Duplicate Values\"):\n",
    "        \"\"\"This function gives us the number of duplicates in the data\"\"\"\n",
    "        print(title.upper())\n",
    "        print(\"-\"*len(title))\n",
    "        try:\n",
    "            print(f\"There are {self.df.duplicated().sum()} duplicated values in this dataset\")\n",
    "        except:\n",
    "            print(\"There was a Type Error: One column has a 'dict' values\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    def null_values(self, title=\"Null Values\"):\n",
    "        \"\"\"This function gives us the number of null values in the data\"\"\"\n",
    "        print(title.upper())\n",
    "        print(\"-\"*len(title))\n",
    "        isnulls = self.df.isnull().sum()\n",
    "        print(f\"There are {isnulls.sum()} null values in this dataset\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(f\"There are {len(isnulls[isnulls > 0])} columns with null values while {len(isnulls[isnulls == 0])}\"\\\n",
    "             +\" do not have null values\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(\"Null Values per column\")\n",
    "        print(isnulls[isnulls > 0])\n",
    "        print(\"\\n\")        \n",
    "        \n",
    "    def unique_values(self, title=\"Unique Values\"):\n",
    "        \"\"\"This function gives us the unique and nunique values in the data\"\"\"\n",
    "        print(title.upper())\n",
    "        print(\"-\"*len(title))\n",
    "        for col in self.df.columns:\n",
    "            print(col)\n",
    "            print(\"-\"*len(col))\n",
    "            try:\n",
    "                print(f\"Number of unique values: {self.df[col].nunique()}\")\n",
    "            except:\n",
    "                print(\"Error - This column has a type error\")\n",
    "            print(\"\\n\")\n",
    "        \n",
    "        \n",
    "    def run_all(self):\n",
    "        self.print_shape()\n",
    "        self.information()\n",
    "        self.duplicate_values()\n",
    "        self.null_values()\n",
    "        self.unique_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dee070db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORD\n",
      "------\n",
      "There are 1000 rows\n",
      "There are 44 columns\n",
      "\n",
      "\n",
      "INFO\n",
      "----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 44 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   report_number                 1000 non-null   object        \n",
      " 1   local_case_number             1000 non-null   int64         \n",
      " 2   agency_name                   1000 non-null   object        \n",
      " 3   acrs_report_type              1000 non-null   object        \n",
      " 4   crash_date_time               1000 non-null   datetime64[ns]\n",
      " 5   number_of_lanes               1000 non-null   object        \n",
      " 6   distance_unit                 1000 non-null   object        \n",
      " 7   off_road_description          133 non-null    object        \n",
      " 8   at_fault                      1000 non-null   object        \n",
      " 9   collision_type                1000 non-null   object        \n",
      " 10  weather                       1000 non-null   object        \n",
      " 11  light                         1000 non-null   object        \n",
      " 12  driver_substance_abuse        993 non-null    object        \n",
      " 13  first_harmful_event           1000 non-null   object        \n",
      " 14  latitude                      1000 non-null   float64       \n",
      " 15  longitude                     1000 non-null   float64       \n",
      " 16  geolocation                   1000 non-null   object        \n",
      " 17  :@computed_region_vu5j_pcmz   998 non-null    float64       \n",
      " 18  :@computed_region_tx5f_5em3   998 non-null    float64       \n",
      " 19  :@computed_region_kbsp_ykn9   998 non-null    float64       \n",
      " 20  :@computed_region_d7bw_bq6x   1000 non-null   int64         \n",
      " 21  :@computed_region_rbt8_3x7n   999 non-null    float64       \n",
      " 22  :@computed_region_a9cs_3ed7   998 non-null    float64       \n",
      " 23  :@computed_region_r648_kzwt   998 non-null    float64       \n",
      " 24  :@computed_region_6vgr_duib   998 non-null    float64       \n",
      " 25  hit_run                       803 non-null    object        \n",
      " 26  lane_direction                862 non-null    object        \n",
      " 27  lane_type                     867 non-null    object        \n",
      " 28  direction                     867 non-null    object        \n",
      " 29  distance                      867 non-null    float64       \n",
      " 30  road_grade                    867 non-null    object        \n",
      " 31  surface_condition             862 non-null    object        \n",
      " 32  traffic_control               867 non-null    object        \n",
      " 33  junction                      847 non-null    object        \n",
      " 34  intersection_type             281 non-null    object        \n",
      " 35  road_alignment                867 non-null    object        \n",
      " 36  road_condition                867 non-null    object        \n",
      " 37  road_division                 867 non-null    object        \n",
      " 38  route_type                    866 non-null    object        \n",
      " 39  road_name                     743 non-null    object        \n",
      " 40  cross_street_name             338 non-null    object        \n",
      " 41  second_harmful_event          189 non-null    object        \n",
      " 42  related_non_motorist          70 non-null     object        \n",
      " 43  non_motorist_substance_abuse  70 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(10), int64(2), object(31)\n",
      "memory usage: 343.9+ KB\n",
      "None\n",
      "\n",
      "\n",
      "DUPLICATE VALUES\n",
      "----------------\n",
      "There was a Type Error: One column has a 'dict' values\n",
      "\n",
      "\n",
      "NULL VALUES\n",
      "-----------\n",
      "There are 7020 null values in this dataset\n",
      "\n",
      "\n",
      "There are 28 columns with null values while 16 do not have null values\n",
      "\n",
      "\n",
      "Null Values per column\n",
      "off_road_description            867\n",
      "driver_substance_abuse            7\n",
      ":@computed_region_vu5j_pcmz       2\n",
      ":@computed_region_tx5f_5em3       2\n",
      ":@computed_region_kbsp_ykn9       2\n",
      ":@computed_region_rbt8_3x7n       1\n",
      ":@computed_region_a9cs_3ed7       2\n",
      ":@computed_region_r648_kzwt       2\n",
      ":@computed_region_6vgr_duib       2\n",
      "hit_run                         197\n",
      "lane_direction                  138\n",
      "lane_type                       133\n",
      "direction                       133\n",
      "distance                        133\n",
      "road_grade                      133\n",
      "surface_condition               138\n",
      "traffic_control                 133\n",
      "junction                        153\n",
      "intersection_type               719\n",
      "road_alignment                  133\n",
      "road_condition                  133\n",
      "road_division                   133\n",
      "route_type                      134\n",
      "road_name                       257\n",
      "cross_street_name               662\n",
      "second_harmful_event            811\n",
      "related_non_motorist            930\n",
      "non_motorist_substance_abuse    930\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "-------------\n",
      "report_number\n",
      "-------------\n",
      "Number of unique values: 1000\n",
      "\n",
      "\n",
      "local_case_number\n",
      "-----------------\n",
      "Number of unique values: 999\n",
      "\n",
      "\n",
      "agency_name\n",
      "-----------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      "acrs_report_type\n",
      "----------------\n",
      "Number of unique values: 3\n",
      "\n",
      "\n",
      "crash_date_time\n",
      "---------------\n",
      "Number of unique values: 981\n",
      "\n",
      "\n",
      "number_of_lanes\n",
      "---------------\n",
      "Number of unique values: 25\n",
      "\n",
      "\n",
      "distance_unit\n",
      "-------------\n",
      "Number of unique values: 1\n",
      "\n",
      "\n",
      "off_road_description\n",
      "--------------------\n",
      "Number of unique values: 132\n",
      "\n",
      "\n",
      "at_fault\n",
      "--------\n",
      "Number of unique values: 4\n",
      "\n",
      "\n",
      "collision_type\n",
      "--------------\n",
      "Number of unique values: 10\n",
      "\n",
      "\n",
      "weather\n",
      "-------\n",
      "Number of unique values: 6\n",
      "\n",
      "\n",
      "light\n",
      "-----\n",
      "Number of unique values: 8\n",
      "\n",
      "\n",
      "driver_substance_abuse\n",
      "----------------------\n",
      "Number of unique values: 22\n",
      "\n",
      "\n",
      "first_harmful_event\n",
      "-------------------\n",
      "Number of unique values: 30\n",
      "\n",
      "\n",
      "latitude\n",
      "--------\n",
      "Number of unique values: 1000\n",
      "\n",
      "\n",
      "longitude\n",
      "---------\n",
      "Number of unique values: 1000\n",
      "\n",
      "\n",
      "geolocation\n",
      "-----------\n",
      "Error - This column has a type error\n",
      "\n",
      "\n",
      ":@computed_region_vu5j_pcmz\n",
      "---------------------------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      ":@computed_region_tx5f_5em3\n",
      "---------------------------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      ":@computed_region_kbsp_ykn9\n",
      "---------------------------\n",
      "Number of unique values: 54\n",
      "\n",
      "\n",
      ":@computed_region_d7bw_bq6x\n",
      "---------------------------\n",
      "Number of unique values: 39\n",
      "\n",
      "\n",
      ":@computed_region_rbt8_3x7n\n",
      "---------------------------\n",
      "Number of unique values: 11\n",
      "\n",
      "\n",
      ":@computed_region_a9cs_3ed7\n",
      "---------------------------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      ":@computed_region_r648_kzwt\n",
      "---------------------------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      ":@computed_region_6vgr_duib\n",
      "---------------------------\n",
      "Number of unique values: 7\n",
      "\n",
      "\n",
      "hit_run\n",
      "-------\n",
      "Number of unique values: 2\n",
      "\n",
      "\n",
      "lane_direction\n",
      "--------------\n",
      "Number of unique values: 20\n",
      "\n",
      "\n",
      "lane_type\n",
      "---------\n",
      "Number of unique values: 59\n",
      "\n",
      "\n",
      "direction\n",
      "---------\n",
      "Number of unique values: 4\n",
      "\n",
      "\n",
      "distance\n",
      "--------\n",
      "Number of unique values: 554\n",
      "\n",
      "\n",
      "road_grade\n",
      "----------\n",
      "Number of unique values: 13\n",
      "\n",
      "\n",
      "surface_condition\n",
      "-----------------\n",
      "Number of unique values: 3\n",
      "\n",
      "\n",
      "traffic_control\n",
      "---------------\n",
      "Number of unique values: 25\n",
      "\n",
      "\n",
      "junction\n",
      "--------\n",
      "Number of unique values: 8\n",
      "\n",
      "\n",
      "intersection_type\n",
      "-----------------\n",
      "Number of unique values: 3\n",
      "\n",
      "\n",
      "road_alignment\n",
      "--------------\n",
      "Number of unique values: 6\n",
      "\n",
      "\n",
      "road_condition\n",
      "--------------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      "road_division\n",
      "-------------\n",
      "Number of unique values: 15\n",
      "\n",
      "\n",
      "route_type\n",
      "----------\n",
      "Number of unique values: 13\n",
      "\n",
      "\n",
      "road_name\n",
      "---------\n",
      "Number of unique values: 403\n",
      "\n",
      "\n",
      "cross_street_name\n",
      "-----------------\n",
      "Number of unique values: 274\n",
      "\n",
      "\n",
      "second_harmful_event\n",
      "--------------------\n",
      "Number of unique values: 21\n",
      "\n",
      "\n",
      "related_non_motorist\n",
      "--------------------\n",
      "Number of unique values: 6\n",
      "\n",
      "\n",
      "non_motorist_substance_abuse\n",
      "----------------------------\n",
      "Number of unique values: 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement the class on the dataframe\n",
    "data = DataUnderstanding(df_accidents)\n",
    "data.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa7f17",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### 1. Standardising Column Names and Values\n",
    "\n",
    "#### 1A. Columns to retain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c79ac093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "accidents_columns = [\n",
    "       'agency_name', 'acrs_report_type',\n",
    "       'crash_date_time', 'number_of_lanes', 'at_fault', 'collision_type', 'weather',\n",
    "       'light', 'driver_substance_abuse', 'first_harmful_event', 'latitude',\n",
    "       'longitude', 'hit_run', 'road_grade', 'surface_condition',\n",
    "       'traffic_control', 'junction', 'intersection_type', 'road_alignment',\n",
    "       'road_condition', 'road_division', 'route_type', 'road_name',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a61eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with the specified columns\n",
    "df = df_accidents[accidents_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6993f8",
   "metadata": {},
   "source": [
    "#### 1B. Drop Some Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99524e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows without critical data i.e where the offroad description was there\n",
    "df = df[(df['road_grade'].isna() != True ) & (df['surface_condition'].isna() != True ) & \n",
    "        (df['traffic_control'].isna() != True )].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5449c0e1",
   "metadata": {},
   "source": [
    "### 2. Too many values \n",
    "\n",
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bfadaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_driver_substance_abuse(df, column_name='driver_substance_abuse'):\n",
    "    \"\"\"\n",
    "    Cleans the 'Driver Substance Abuse' column by mapping unique values to key phrases.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        # Alcohol\n",
    "        'ALCOHOL PRESENT': 'Alcohol',\n",
    "        'ALCOHOL CONTRIBUTED': 'Alcohol',\n",
    "        'ALCOHOL PRESENT, N/A': 'Alcohol',\n",
    "        'ALCOHOL CONTRIBUTED, N/A': 'Alcohol',\n",
    "        'ALCOHOL PRESENT, NONE DETECTED': 'Alcohol',\n",
    "        'ALCOHOL CONTRIBUTED, NONE DETECTED': 'Alcohol',\n",
    "        'ALCOHOL PRESENT, N/A, NONE DETECTED': 'Alcohol',\n",
    "        'ALCOHOL PRESENT, UNKNOWN': 'Alcohol',\n",
    "        'ALCOHOL CONTRIBUTED, UNKNOWN': 'Alcohol',\n",
    "        'ALCOHOL PRESENT, NONE DETECTED, UNKNOWN': 'Alcohol',\n",
    "        'ALCOHOL CONTRIBUTED, NONE DETECTED, UNKNOWN': 'Alcohol',\n",
    "        'ALCOHOL PRESENT, N/A, UNKNOWN': 'Alcohol',\n",
    "        'ALCOHOL CONTRIBUTED, N/A, NONE DETECTED': 'Alcohol',\n",
    "        'ALCOHOL PRESENT, ILLEGAL DRUG PRESENT': 'Alcohol, Illegal Drugs',\n",
    "        'Suspect of Alcohol Use, Not Suspect of Drug Use': 'Alcohol',\n",
    "        'Suspect of Alcohol Use, Unknown': 'Alcohol',\n",
    "        'Suspect of Alcohol Use, Suspect of Drug Use': 'Alcohol, Illegal Drugs',\n",
    "        'Suspect of Alcohol Use, Suspect of Drug Use, Unknown, Not Suspect of Drug Use': 'Alcohol, Illegal Drugs',\n",
    "        'Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Unknown': 'Alcohol',\n",
    "        'Suspect of Alcohol Use, Not Suspect of Drug Use, Suspect of Alcohol Use, Not Suspect of Drug Use': 'Alcohol',\n",
    "        'Suspect of Alcohol Use, Unknown, Unknown, Unknown': 'Alcohol',\n",
    "        \n",
    "        # Drugs\n",
    "        'ILLEGAL DRUG CONTRIBUTED, NONE DETECTED': 'Illegal Drugs',\n",
    "        'ILLEGAL DRUG PRESENT, NONE DETECTED': 'Illegal Drugs',\n",
    "        'ILLEGAL DRUG PRESENT': 'Illegal Drugs',\n",
    "        'ILLEGAL DRUG CONTRIBUTED': 'Illegal Drugs',\n",
    "        'ILLEGAL DRUG PRESENT, N/A': 'Illegal Drugs',\n",
    "        'ILLEGAL DRUG CONTRIBUTED, N/A': 'Illegal Drugs',\n",
    "        'ILLEGAL DRUG PRESENT, N/A, NONE DETECTED': 'Illegal Drugs',\n",
    "        'ILLEGAL DRUG PRESENT, UNKNOWN': 'Illegal Drugs',\n",
    "        'Not Suspect of Alcohol Use, Suspect of Drug Use': 'Illegal Drugs',\n",
    "        'Unknown, Not Suspect of Drug Use': 'Illegal Drugs',\n",
    "        'Not Suspect of Alcohol Use, Suspect of Drug Use, Unknown, Unknown': 'Illegal Drugs',\n",
    "        'Not Suspect of Alcohol Use, Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Illegal Drugs',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Suspect of Drug Use': 'Illegal Drugs',\n",
    "        'Suspect of Alcohol Use, Suspect of Drug Use, Unknown, Unknown': 'Alcohol, Illegal Drugs',\n",
    "        'Unknown, Suspect of Drug Use': 'Illegal Drugs',\n",
    "\n",
    "        # Medication\n",
    "        'MEDICATION PRESENT, NONE DETECTED': 'Medication',\n",
    "        'MEDICATION PRESENT': 'Medication',\n",
    "        'MEDICATION CONTRIBUTED, NONE DETECTED, UNKNOWN': 'Medication',\n",
    "        'MEDICATION CONTRIBUTED, NONE DETECTED': 'Medication',\n",
    "        'MEDICATION CONTRIBUTED, UNKNOWN': 'Medication',\n",
    "        'MEDICATION PRESENT, N/A': 'Medication',\n",
    "        'MEDICATION CONTRIBUTED': 'Medication',\n",
    "        'MEDICATION CONTRIBUTED, N/A': 'Medication',\n",
    "        'MEDICATION PRESENT, NONE DETECTED, UNKNOWN': 'Medication',\n",
    "        'MEDICATION PRESENT, N/A, UNKNOWN': 'Medication',\n",
    "\n",
    "        # Combined drugs\n",
    "        'COMBINATION CONTRIBUTED, N/A': 'Combined Substance',\n",
    "        'COMBINED SUBSTANCE PRESENT, NONE DETECTED': 'Combined Substance',\n",
    "        'COMBINED SUBSTANCE PRESENT': 'Combined Substance',\n",
    "        'COMBINED SUBSTANCE PRESENT, N/A': 'Combined Substance',\n",
    "        'COMBINATION CONTRIBUTED, NONE DETECTED': 'Combined Substance',\n",
    "        'COMBINED SUBSTANCE PRESENT, UNKNOWN': 'Combined Substance',\n",
    "        'COMBINED SUBSTANCE PRESENT, N/A, NONE DETECTED': 'Combined Substance',\n",
    "        'COMBINATION CONTRIBUTED': 'Combined Substance',\n",
    "\n",
    "        # No drugs or Alcohol\n",
    "        'NONE DETECTED': 'None Detected',\n",
    "        'N/A, NONE DETECTED': 'None Detected',\n",
    "        'NONE DETECTED, UNKNOWN': 'None Detected',\n",
    "        'N/A, NONE DETECTED, UNKNOWN': 'None Detected',\n",
    "\n",
    "        # Unknown\n",
    "        'UNKNOWN': 'Unknown',\n",
    "        'N/A, UNKNOWN': 'Unknown',\n",
    "         np.nan: 'Unknown',\n",
    "        'Unknown, Unknown': 'Unknown',\n",
    "        'Unknown, Unknown, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Unknown, Unknown, Unknown': 'Unknown',\n",
    "        'Unknown, Unknown, Unknown, Unknown, Unknown, Unknown': 'Unknown',\n",
    "        'Unknown, Unknown, Unknown, Unknown, Unknown, Unknown, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Unknown, Unknown, Unknown, Unknown, Unknown': 'Unknown',\n",
    "        'Unknown, Not Suspect of Drug Use, Unknown, Unknown': 'Unknown',\n",
    "        'Suspect of Alcohol Use, Unknown, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Unknown, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Unknown, Not Suspect of Alcohol Use, Unknown, Not Suspect of Alcohol Use, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Not Suspect of Drug Use': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Unknown': 'Unknown',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Unknown, Not Suspect of Drug Use': 'Unknown',\n",
    "        'Unknown, Not Suspect of Drug Use, Unknown, Unknown': 'Unknown',\n",
    "\n",
    "        # Not Suspected\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Suspect of Alcohol Use, Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Suspect of Alcohol Use, Unknown': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Suspect of Alcohol Use, Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Not Suspect of Drug Use, Not Suspect of Alcohol Use, Not Suspect of Drug Use, Suspect of Alcohol Use, Suspect of Drug Use': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Unknown': 'Not Suspected',\n",
    "        'Not Suspect of Alcohol Use, Unknown, Not Suspect of Alcohol Use, Not Suspect of Drug Use': 'Not Suspected',\n",
    "\n",
    "        # Others\n",
    "        'OTHER': 'Other',\n",
    "        'N/A, OTHER': 'Other',\n",
    "        'NONE DETECTED, OTHER': 'Other',\n",
    "    }\n",
    "\n",
    "    # The mapping function - any null items are filled using 'Other'\n",
    "    df.loc[:, column_name] = df[column_name].map(mapping).fillna('Other')\n",
    "\n",
    "    print(df[column_name].unique())\n",
    "    \n",
    "def clean_traffic_control(df, column_name='Traffic Control'):\n",
    "    \"\"\"\n",
    "    Cleans the Traffic Control column by mapping unique values to key phrases.\n",
    "    \"\"\"\n",
    "    # No/Unknown/Miscellaneous Control\n",
    "    mapping = {\n",
    "    'No Controls': 'No/Unknown/Miscellaneous Control',\n",
    "    'Unknown': 'No/Unknown/Miscellaneous Control',\n",
    "    'Other': 'No/Unknown/Miscellaneous Control',\n",
    "    'Other Signal': 'No/Unknown/Miscellaneous Control',\n",
    "    'Other Pavement Marking (Excluding Edgelines, Centerlines, Or Lane Lines)': 'No/Unknown/Miscellaneous Control',\n",
    "    'School Zone': 'No/Unknown/Miscellaneous Control', # If it's a general area description\n",
    "\n",
    "    # Signs\n",
    "    'Stop Sign': 'Signs',\n",
    "    'Yield Sign': 'Signs',\n",
    "    'Warning Sign': 'Signs',\n",
    "    'School Zone Sign Device': 'Signs',\n",
    "    'School Zone Sign': 'Signs',\n",
    "    'Pedestrian Crossing Sign': 'Signs',\n",
    "    'Bicycle Crossing Sign': 'Signs',\n",
    "    'Intersection Ahead Warning Sign': 'Signs',\n",
    "    'Curve Ahead Warning Sign': 'Signs',\n",
    "    'Reduce Speed Ahead Warning Sign': 'Signs',\n",
    "    'Other Warning Sign': 'Signs',\n",
    "\n",
    "    # Traffic Signals\n",
    "    'Traffic Signal': 'Traffic Signals',\n",
    "    'Flashing Traffic Signal': 'Traffic Signals',\n",
    "    'Traffic Control Signal': 'Traffic Signals',\n",
    "    'Flashing Traffic Control Signal': 'Traffic Signals',\n",
    "    'Ramp Meter Signal': 'Traffic Signals',\n",
    "    'Lane Use Control Signal': 'Traffic Signals',\n",
    "\n",
    "    # Railroad Crossing Devices\n",
    "    'Railway Crossing Device': 'Railroad Crossing Devices',\n",
    "    'Flashing Railroad Crossing Signal (May Include Gates)': 'Railroad Crossing Devices',\n",
    "\n",
    "    # Human/Pedestrian Control\n",
    "    'Person': 'Human/Pedestrian Control',\n",
    "    'Person (Including Flagger, Law Enforcement, Crossing Guard, Etc.': 'Human/Pedestrian Control',\n",
    "    'Pedestrian Crossing': 'Human/Pedestrian Control'\n",
    "    }\n",
    "        \n",
    "    # The mapping function - any null items are filled using 'Other'\n",
    "    df.loc[:, column_name] = df[column_name].map(mapping).fillna('Other') \n",
    "\n",
    "    print(df[column_name].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006cc7a9",
   "metadata": {},
   "source": [
    "#### 2A. Clean The Driver Substance Abuse Col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efa3fb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Suspected' 'Unknown' 'Alcohol' 'Other' 'Alcohol, Illegal Drugs'\n",
      " 'Illegal Drugs']\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning function\n",
    "clean_driver_substance_abuse(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b1383c",
   "metadata": {},
   "source": [
    "#### 2B. Normalise all values in the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76b01b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only the categorical columns\n",
    "categorical_cols = list(df.select_dtypes('O').columns)\n",
    "categorical_cols\n",
    "\n",
    "# # Standardise values in the categorical columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].apply(lambda x: x.title() if type(x) == str else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4c792",
   "metadata": {},
   "source": [
    "#### 2C. Clean the Traffic Control Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfaf9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Signs' 'Other' 'No/Unknown/Miscellaneous Control' 'Traffic Signals'\n",
      " 'Human/Pedestrian Control']\n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning on the traffic control column\n",
    "clean_traffic_control(df, 'traffic_control')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca9896",
   "metadata": {},
   "source": [
    "### 3. Replace NANs with specified value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c5ddbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_values(replacing_dict:dict):\n",
    "    \"\"\"\n",
    "    This function uses the column (key) plus the replacement value (value) from the \n",
    "    dictionary provided to eradicate nulls from the data\n",
    "    \"\"\"\n",
    "    for column, value in replacing_dict.items():\n",
    "        df.loc[:, column] = df[column].apply(lambda x: value if type(x) != str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f0912ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with the column and replacement value for any nulls\n",
    "replace_dictionary = {\n",
    "    'intersection_type': \"Non-Intersection\", \n",
    "    \"hit_run\": \"Unknown\", \n",
    "    \"road_name\": 'Undisclosed'\n",
    "}\n",
    "\n",
    "# Apply the created function\n",
    "replace_values(replacing_dict=replace_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227c280a",
   "metadata": {},
   "source": [
    "### 4. Fill Null Values with Most common Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67445e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junction missing values 0\n",
      "route_type missing values 0\n"
     ]
    }
   ],
   "source": [
    "# Columns with null values that should be filled with the mode\n",
    "fill_null_columns = ['junction', 'route_type']\n",
    "\n",
    "for col in fill_null_columns:\n",
    "    col_mode = df[col].mode()[0] # Get the mode of the column\n",
    "    df.loc[:, col] = df[col].fillna(col_mode) # Fill with the mode\n",
    "    \n",
    "# Check\n",
    "for col in fill_null_columns:\n",
    "    print(col, \"missing values\", df[col].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac980711",
   "metadata": {},
   "source": [
    "### 5. Final Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0433543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORD\n",
      "------\n",
      "There are 862 rows\n",
      "There are 23 columns\n",
      "\n",
      "\n",
      "INFO\n",
      "----\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 862 entries, 1 to 999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype         \n",
      "---  ------                  --------------  -----         \n",
      " 0   agency_name             862 non-null    object        \n",
      " 1   acrs_report_type        862 non-null    object        \n",
      " 2   crash_date_time         862 non-null    datetime64[ns]\n",
      " 3   number_of_lanes         862 non-null    object        \n",
      " 4   at_fault                862 non-null    object        \n",
      " 5   collision_type          862 non-null    object        \n",
      " 6   weather                 862 non-null    object        \n",
      " 7   light                   862 non-null    object        \n",
      " 8   driver_substance_abuse  862 non-null    object        \n",
      " 9   first_harmful_event     862 non-null    object        \n",
      " 10  latitude                862 non-null    float64       \n",
      " 11  longitude               862 non-null    float64       \n",
      " 12  hit_run                 862 non-null    object        \n",
      " 13  road_grade              862 non-null    object        \n",
      " 14  surface_condition       862 non-null    object        \n",
      " 15  traffic_control         862 non-null    object        \n",
      " 16  junction                862 non-null    object        \n",
      " 17  intersection_type       862 non-null    object        \n",
      " 18  road_alignment          862 non-null    object        \n",
      " 19  road_condition          862 non-null    object        \n",
      " 20  road_division           862 non-null    object        \n",
      " 21  route_type              862 non-null    object        \n",
      " 22  road_name               862 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(2), object(20)\n",
      "memory usage: 161.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "DUPLICATE VALUES\n",
      "----------------\n",
      "There are 0 duplicated values in this dataset\n",
      "\n",
      "\n",
      "NULL VALUES\n",
      "-----------\n",
      "There are 0 null values in this dataset\n",
      "\n",
      "\n",
      "There are 0 columns with null values while 23 do not have null values\n",
      "\n",
      "\n",
      "Null Values per column\n",
      "Series([], dtype: int64)\n",
      "\n",
      "\n",
      "UNIQUE VALUES\n",
      "-------------\n",
      "agency_name\n",
      "-----------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      "acrs_report_type\n",
      "----------------\n",
      "Number of unique values: 3\n",
      "\n",
      "\n",
      "crash_date_time\n",
      "---------------\n",
      "Number of unique values: 849\n",
      "\n",
      "\n",
      "number_of_lanes\n",
      "---------------\n",
      "Number of unique values: 25\n",
      "\n",
      "\n",
      "at_fault\n",
      "--------\n",
      "Number of unique values: 4\n",
      "\n",
      "\n",
      "collision_type\n",
      "--------------\n",
      "Number of unique values: 10\n",
      "\n",
      "\n",
      "weather\n",
      "-------\n",
      "Number of unique values: 6\n",
      "\n",
      "\n",
      "light\n",
      "-----\n",
      "Number of unique values: 8\n",
      "\n",
      "\n",
      "driver_substance_abuse\n",
      "----------------------\n",
      "Number of unique values: 6\n",
      "\n",
      "\n",
      "first_harmful_event\n",
      "-------------------\n",
      "Number of unique values: 28\n",
      "\n",
      "\n",
      "latitude\n",
      "--------\n",
      "Number of unique values: 862\n",
      "\n",
      "\n",
      "longitude\n",
      "---------\n",
      "Number of unique values: 862\n",
      "\n",
      "\n",
      "hit_run\n",
      "-------\n",
      "Number of unique values: 3\n",
      "\n",
      "\n",
      "road_grade\n",
      "----------\n",
      "Number of unique values: 13\n",
      "\n",
      "\n",
      "surface_condition\n",
      "-----------------\n",
      "Number of unique values: 3\n",
      "\n",
      "\n",
      "traffic_control\n",
      "---------------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      "junction\n",
      "--------\n",
      "Number of unique values: 8\n",
      "\n",
      "\n",
      "intersection_type\n",
      "-----------------\n",
      "Number of unique values: 4\n",
      "\n",
      "\n",
      "road_alignment\n",
      "--------------\n",
      "Number of unique values: 6\n",
      "\n",
      "\n",
      "road_condition\n",
      "--------------\n",
      "Number of unique values: 5\n",
      "\n",
      "\n",
      "road_division\n",
      "-------------\n",
      "Number of unique values: 15\n",
      "\n",
      "\n",
      "route_type\n",
      "----------\n",
      "Number of unique values: 13\n",
      "\n",
      "\n",
      "road_name\n",
      "---------\n",
      "Number of unique values: 404\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save Cleaned Dataset\n",
    "df_cleaned = df.to_csv('cleaned_data.csv')\n",
    "\n",
    "cleaned_df = DataUnderstanding(df)\n",
    "cleaned_df.run_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad91b0b",
   "metadata": {},
   "source": [
    "## Data Warehousing\n",
    "\n",
    "This section focuses on creating fact tables and dimension tables. This follows the star schema model. \n",
    "\n",
    "The star schema is used because it is:\n",
    "- Reusable\n",
    "- Optimises efficiency\n",
    "- Scalable\n",
    "- Enhances digital integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a7672f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mappings(df, cat_cols):\n",
    "    \"\"\"\n",
    "    This function creates a mapping of the datasets categorical columns' unique values.\n",
    "    It returns a list full of the mappings per categorical column\n",
    "    \"\"\"\n",
    "\n",
    "    # Stores the lists created\n",
    "    mapping_dictionary  = []\n",
    "\n",
    "    # For each categorical column create a mapping of the values and assign numbers to it\n",
    "    for col in categorical_columns:\n",
    "        mapping_dictionary.append(\n",
    "            {\n",
    "                col: {value: key for key, value in dict(enumerate(df[col].unique(), 1)).items()}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "    return mapping_dictionary \n",
    "\n",
    "def retrieve_map(col):\n",
    "    \"\"\"This function retrieves one map dictionary for a specified column\"\"\"\n",
    "    for map in df_mappings:\n",
    "        for key, value in map.items():\n",
    "            if key == col:\n",
    "                return value\n",
    "            \n",
    "def replace_mapped_values(column_to_be_mapped, mapping_list, df=df):\n",
    "    \"\"\"\n",
    "    This function maps the each columns' value to the map provided in the mapping variable.\n",
    "    This will turn the categorical values into numerical values\n",
    "    \"\"\"\n",
    "    # Retrieves one map for the column chosen\n",
    "    column_specific_map = retrieve_map(column_to_be_mapped)\n",
    "    \n",
    "    # Makes the actual mapping\n",
    "    df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea4189",
   "metadata": {},
   "source": [
    "### <i>Fact Table<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56517760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a seperate copy of the cleaned data\n",
    "mapped_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "120dbb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the categorical columns\n",
    "categorical_columns = list(mapped_df.select_dtypes('O'))\n",
    "\n",
    "# Apply the create mappings function\n",
    "df_mappings = create_mappings(mapped_df, categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adc48010",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n",
      "<ipython-input-18-06f36cbd61de>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df.loc[:, column_to_be_mapped] = df[column_to_be_mapped].map(column_specific_map)\n"
     ]
    }
   ],
   "source": [
    "# Apply mapping to the new dataframe\n",
    "for col in categorical_columns:\n",
    "    replace_mapped_values(column_to_be_mapped=col, mapping_list=df_mappings, df=mapped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31f77794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_harmful_event</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hit_run</th>\n",
       "      <th>road_grade</th>\n",
       "      <th>surface_condition</th>\n",
       "      <th>traffic_control</th>\n",
       "      <th>junction</th>\n",
       "      <th>intersection_type</th>\n",
       "      <th>road_alignment</th>\n",
       "      <th>road_condition</th>\n",
       "      <th>road_division</th>\n",
       "      <th>route_type</th>\n",
       "      <th>road_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39.004033</td>\n",
       "      <td>-77.040995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>39.019026</td>\n",
       "      <td>-77.015578</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39.122000</td>\n",
       "      <td>-77.115599</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>39.001233</td>\n",
       "      <td>-77.123193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>39.044978</td>\n",
       "      <td>-77.111125</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_harmful_event   latitude  longitude  hit_run  road_grade  \\\n",
       "1                    1  39.004033 -77.040995        1           1   \n",
       "3                    1  39.019026 -77.015578        1           2   \n",
       "4                    2  39.122000 -77.115599        1           2   \n",
       "6                    1  39.001233 -77.123193        1           1   \n",
       "7                    1  39.044978 -77.111125        1           3   \n",
       "\n",
       "   surface_condition  traffic_control  junction  intersection_type  \\\n",
       "1                  1                1         1                  1   \n",
       "3                  1                2         1                  1   \n",
       "4                  1                3         2                  2   \n",
       "6                  2                2         1                  3   \n",
       "7                  2                4         2                  2   \n",
       "\n",
       "   road_alignment  road_condition  road_division  route_type  road_name  \n",
       "1               1               1              1           1          1  \n",
       "3               1               1              1           1          2  \n",
       "4               1               1              2           1          3  \n",
       "6               1               1              3           1          4  \n",
       "7               2               1              4           1          5  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "mapped_df.iloc[:5, 9:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fe3a444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Fact Table as csv\n",
    "mapped_df.reset_index(inplace=True, drop=True)\n",
    "mapped_df.index = mapped_df.index + 1\n",
    "mapped_df.head()\n",
    "crash_data_fact_table = mapped_df.to_csv('crash_data_fact_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32b0ac",
   "metadata": {},
   "source": [
    "### <i>Dimension Tables<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f336def2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_name_ID</th>\n",
       "      <th>agency_name_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Montgomery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Takoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rockville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gaithersburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mcpark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agency_name_ID agency_name_Status\n",
       "0               1         Montgomery\n",
       "1               2             Takoma\n",
       "2               3          Rockville\n",
       "3               4       Gaithersburg\n",
       "4               5             Mcpark"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty Dictionary for holding the dataframes\n",
    "dimensions_dictionary = {}\n",
    "\n",
    "# Each categorical column will create a dictionary of unique values with an index\n",
    "for col in categorical_columns:\n",
    "    col_renamed = col.replace(' ', '_') # Format the col value\n",
    "    columns = [col_renamed+'_ID', col_renamed+'_Status'] # Columns of the DataFrame\n",
    "    col_mapped_dictionary = dict(enumerate(df[col].unique(), 1)) # Dictionary of index and unique values\n",
    "    dataframe = pd.DataFrame(col_mapped_dictionary.items(), columns=columns) # Create dataframe\n",
    "    dimensions_dictionary[col_renamed] = dataframe # Save dataframe in the dimensions_dictionary\n",
    "\n",
    "# Check\n",
    "dimensions_dictionary['agency_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d3187",
   "metadata": {},
   "source": [
    "### Postgres Quick Query Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e812f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query will create a text that will create the fact table using PostgreSQL syntax\n",
    "for col in mapped_df.columns:\n",
    "    if col not in ['crash_date_time', 'latitude', 'longitude']:\n",
    "        table_name = 'dim_' + col\n",
    "        table_name = dimensions_dictionary[col].to_csv(f\"{table_name}.csv\")\n",
    "        text = \\\n",
    "        f\"\"\" \n",
    "        DROP TABLE IF EXISTS {col};\n",
    "        CREATE TABLE {col}(\n",
    "            id SERIAL PRIMARY KEY,\n",
    "            {dimensions_dictionary[col].columns[0]} INT,\n",
    "            {dimensions_dictionary[col].columns[1]} VARCHAR(255)            \n",
    "        );\n",
    "        \"\"\"\n",
    "        print(text)\n",
    "        print()\n",
    "   \n",
    "# This query will create a text that will upload the dimension data csvs using PostgreSQL syntax - use it in psql tool\n",
    "for col in mapped_df.columns:\n",
    "    if col not in ['crash_date_time', 'latitude', 'longitude']:\n",
    "        table_name = 'dim_' + col\n",
    "        text = \\\n",
    "        f\"\"\"\\COPY {col} FROM 'C:\\\\Users\\\\PROBOOK 6460\\\\Documents\\\\EU BUSINESS SCHOOL\\\\Business Intelligence\\\\Final Project\\\\{table_name}.csv' WITH CSV HEADER;\n",
    "        \"\"\"\n",
    "        print(text)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
